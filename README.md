# Text Embeddings (embeddings.py File)
This project demonstrates how to use Keras to create embeddings for text data. The code showcases the process of converting text into a numeric representation using one-hot encoding, padding the sequences, and then applying an Embedding layer to obtain dense vector representations of the text.

## Prerequisites

Before running the code, ensure you have the following libraries installed:

- TensorFlow
- NumPy
- Pandas

You can install these libraries using pip:

```bash
pip install tensorflow numpy pandas
```

## Project Structure

- **sent**: A list of sentences that will be used for the demonstration.
- **voc_size**: The vocabulary size used for one-hot encoding.
- **one_hot_rep**: The one-hot encoded representation of the sentences.
- **sent_length**: The maximum length of the padded sentences.
- **embedded_docs**: The padded sequences of the one-hot encoded sentences.
- **dim**: The dimension of the dense vector in the embedding layer.
- **model**: The Keras Sequential model with an Embedding layer.

## Steps

1. **Text Data Preparation**: A list of sentences (`sent`) is prepared for demonstration.
2. **One-Hot Encoding**: The sentences are converted to a one-hot encoded representation using the `one_hot` function from `tensorflow.keras.preprocessing.text`.
3. **Padding Sequences**: The one-hot encoded sentences are padded to ensure they have the same length (`sent_length`). This is done using the `pad_sequences` function from `tensorflow.keras.utils`.
4. **Embedding Layer**: A Keras Sequential model is created, and an Embedding layer is added to convert the padded sequences into dense vectors of a specified dimension (`dim`).
5. **Model Compilation**: The model is compiled using the Adam optimizer and Mean Squared Error (MSE) as the loss function.
6. **Model Summary**: A summary of the model architecture is printed.
7. **Prediction**: The model is used to predict the embeddings for the input sentences.

## Running the Code

To run the code, simply execute the Python script. It will display the one-hot encoded representations, the padded sequences, and the model's summary. Additionally, it will output the embeddings generated by the model.

```bash
python embedding_example.py
```

## Output

- **One-Hot Representation**: Displays the one-hot encoded numeric representation of each sentence.
- **Padded Sequences**: Shows the padded sequences after applying `pad_sequences`.
- **Model Summary**: Provides a summary of the model, including the Embedding layer.
- **Predicted Embeddings**: Outputs the dense vector representations of the input sentences.

## Conclusion

This example demonstrates the process of text embedding using Keras. The embeddings generated by the model can be used as features for various NLP tasks such as text classification, sentiment analysis, and more.
